{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42cdeddc-a55c-43dc-9ffc-3594eab2a1c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# <font color='blue'>Traductor de idiomas con aprendizaje automático y NLP</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a933645-8888-4e34-852c-1fa4bfea670c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión del lenguaje Python utilizada en este Jupyter Notebook: 3.9.5\n"
     ]
    }
   ],
   "source": [
    "# Versión del lenguaje Python\n",
    "# from platform import python_version\n",
    "print('Versión del lenguaje Python utilizada en este Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7fe4878-1f93-43bf-aefa-2db16a98cc9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Para actualizar un paquete, ejecute el siguiente comando en una terminal o símbolo del sistema:\n",
    "# pip install -U nombre_paquete\n",
    "\n",
    "# Para instalar la versión exacta de un paquete, ejecute el siguiente comando en una terminal o símbolo del sistema:\n",
    "# !pip instalar antorcha==1.5.0\n",
    "\n",
    "# Después de instalar o actualizar el paquete, reinicie el cuaderno jupyter.\n",
    "\n",
    "# Instale el paquete de marca de agua.\n",
    "# Este paquete se usa para escribir versiones de otros paquetes usados ​​en este cuaderno jupyter.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f31f8502-c35b-46fa-92e6-61d6cf9fe014",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-d78c7c25-a401-4b32-ab5e-4bd2dcb2a79d/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Instalar PyTorch\n",
    "!pip install -q torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8357e119-db32-4ffd-a361-4deb3609943d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\ntorchvision 0.13.1+cpu requires torch==1.12.1, but you have torch 2.0.1 which is incompatible.\u001B[0m\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-d78c7c25-a401-4b32-ab5e-4bd2dcb2a79d/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "# El paquete torchtext proporciona varios conjuntos de datos y funciones para NLP\n",
    "# https://torchtext.readthedocs.io/en/latest/index.html\n",
    "!pip install -q torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e45417ab-034a-463c-a97a-43fb998da089",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-d78c7c25-a401-4b32-ab5e-4bd2dcb2a79d/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Instalar o spacy\n",
    "!pip install -q spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "625947e9-5862-4ef4-8df4-d61696596698",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)\n",
       "\u001B[0;32m<command-3352856648243565>\u001B[0m in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorchtext\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtorchtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasets\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mMulti30k\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 12\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtorchtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mField\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBucketIterator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\n",
       "\u001B[0;31mImportError\u001B[0m: cannot import name 'Field' from 'torchtext.data' (/local_disk0/.ephemeral_nfs/envs/pythonEnv-d78c7c25-a401-4b32-ab5e-4bd2dcb2a79d/lib/python3.9/site-packages/torchtext/data/__init__.py)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)\n\u001B[0;32m<command-3352856648243565>\u001B[0m in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorchtext\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtorchtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasets\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mMulti30k\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtorchtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mField\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBucketIterator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;31mImportError\u001B[0m: cannot import name 'Field' from 'torchtext.data' (/local_disk0/.ephemeral_nfs/envs/pythonEnv-d78c7c25-a401-4b32-ab5e-4bd2dcb2a79d/lib/python3.9/site-packages/torchtext/data/__init__.py)",
       "errorSummary": "<span class='ansi-red-fg'>ImportError</span>: cannot import name 'Field' from 'torchtext.data' (/local_disk0/.ephemeral_nfs/envs/pythonEnv-d78c7c25-a401-4b32-ab5e-4bd2dcb2a79d/lib/python3.9/site-packages/torchtext/data/__init__.py)",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import math\n",
    "import time\n",
    "import spacy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df2d90bc-d149-4369-ae9a-8b951a47a9b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n",
       "\u001B[0;32m<command-3352856648243566>\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[0;31m# Versões dos pacotes usados neste jupyter notebook\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m----> 2\u001B[0;31m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'reload_ext'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'watermark'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'watermark'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'-a \"Eric Passos\" --iversions'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mrun_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n",
       "\u001B[1;32m   2405\u001B[0m                 \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'local_ns'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_local_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstack_depth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   2406\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuiltin_trap\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 2407\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m   2408\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   2409\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/decorator.py\u001B[0m in \u001B[0;36mfun\u001B[0;34m(*args, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mkwsyntax\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    231\u001B[0m                 \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 232\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mcaller\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mextras\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    233\u001B[0m     \u001B[0mfun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    234\u001B[0m     \u001B[0mfun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__doc__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__doc__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/IPython/core/magic.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(f, *a, **k)\u001B[0m\n",
       "\u001B[1;32m    185\u001B[0m     \u001B[0;31m# but it's overkill for just that one bit of state.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    186\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmagic_deco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 187\u001B[0;31m         \u001B[0mcall\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    189\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/IPython/core/magics/extension.py\u001B[0m in \u001B[0;36mreload_ext\u001B[0;34m(self, module_str)\u001B[0m\n",
       "\u001B[1;32m     61\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mmodule_str\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     62\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mUsageError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Missing module name.'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 63\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshell\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextension_manager\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreload_extension\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/IPython/core/extensions.py\u001B[0m in \u001B[0;36mreload_extension\u001B[0;34m(self, module_str)\u001B[0m\n",
       "\u001B[1;32m    128\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloaded\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    129\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 130\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_extension\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    131\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    132\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_call_load_ipython_extension\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmod\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/IPython/core/extensions.py\u001B[0m in \u001B[0;36mload_extension\u001B[0;34m(self, module_str)\u001B[0m\n",
       "\u001B[1;32m     78\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mmodule_str\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodules\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     79\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mprepended_to_syspath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mipython_extension_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 80\u001B[0;31m                     \u001B[0mmod\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimport_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m     81\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mmod\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__file__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mipython_extension_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     82\u001B[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
       "\n",
       "\u001B[0;32m/usr/lib/python3.9/importlib/__init__.py\u001B[0m in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n",
       "\u001B[1;32m    125\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    126\u001B[0m             \u001B[0mlevel\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 127\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_bootstrap\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_gcd_import\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpackage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    128\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
       "\n",
       "\u001B[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
       "\n",
       "\u001B[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
       "\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'watermark'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n\u001B[0;32m<command-3352856648243566>\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Versões dos pacotes usados neste jupyter notebook\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'reload_ext'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'watermark'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'watermark'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'-a \"Eric Passos\" --iversions'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mrun_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[1;32m   2405\u001B[0m                 \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'local_ns'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_local_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstack_depth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2406\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuiltin_trap\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2407\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2408\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2409\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/decorator.py\u001B[0m in \u001B[0;36mfun\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mkwsyntax\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    231\u001B[0m                 \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 232\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mcaller\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mextras\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    233\u001B[0m     \u001B[0mfun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m     \u001B[0mfun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__doc__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__doc__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/IPython/core/magic.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(f, *a, **k)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[0;31m# but it's overkill for just that one bit of state.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmagic_deco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m         \u001B[0mcall\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/IPython/core/magics/extension.py\u001B[0m in \u001B[0;36mreload_ext\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m     61\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mmodule_str\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mUsageError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Missing module name.'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshell\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextension_manager\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreload_extension\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/IPython/core/extensions.py\u001B[0m in \u001B[0;36mreload_extension\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m    128\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloaded\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 130\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_extension\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    131\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_call_load_ipython_extension\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmod\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/IPython/core/extensions.py\u001B[0m in \u001B[0;36mload_extension\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m     78\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mmodule_str\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodules\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mprepended_to_syspath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mipython_extension_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m                     \u001B[0mmod\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimport_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mmod\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__file__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mipython_extension_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n\n\u001B[0;32m/usr/lib/python3.9/importlib/__init__.py\u001B[0m in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    125\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m             \u001B[0mlevel\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 127\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_bootstrap\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_gcd_import\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpackage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    128\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n\n\u001B[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n\n\u001B[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n\n\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'watermark'",
       "errorSummary": "<span class='ansi-red-fg'>ModuleNotFoundError</span>: No module named 'watermark'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Versiones de paquetes utilizados en este cuaderno jupyter\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Eric Passos\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1483269-2952-4698-b482-8b847dd92687",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aquí definimos el dispositivo que se usará para entrenar el modelo\n",
    "# Si hay al menos una GPU disponible, usaremos el dispositivo 'cuda' (nombre de plataforma Nvidia para GPU)\n",
    "# Si no hay GPU, usaremos CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "693b4d7a-48f5-45ed-9131-1706d43417cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "El siguiente comando funcionará solo si la plataforma CUDA de Nivida está instalada en la computadora. Si quieres saber más sobre la plataforma CUDA, visita aquí:\n",
    "https://developer.nvidia.com/cuda-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b6d1ff3-b917-47ed-942c-da97bfcf17f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 21 21:49:41 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN X (Pascal)    On   | 00000000:05:00.0 Off |                  N/A |\r\n| 23%   41C    P8     9W / 250W |    125MiB / 12194MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  On   | 00000000:09:00.0 Off |                  N/A |\r\n| 23%   38C    P8     9W / 250W |     12MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  TITAN RTX           On   | 00000000:0B:00.0 Off |                  N/A |\r\n| 41%   39C    P8    13W / 280W |     12MiB / 24220MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1578      G   /usr/lib/xorg/Xorg                            39MiB |\r\n|    0      1614      G   /usr/bin/gnome-shell                          72MiB |\r\n+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# GPU en el servidor\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cad7a1f-1772-494e-a720-9c9fb0d82445",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Diccionarios\n",
    "\n",
    "Necesitamos instalar los diccionarios de idioma que se utilizarán para entrenar el modelo. Aquí puede encontrar detalles sobre los conjuntos de datos:\n",
    "\n",
    "https://www.statmt.org/wmt16/multimodal-task.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b77d6df-a907-4052-8461-7f32f3ae7874",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (2.2.5)\nRequirement already satisfied: spacy>=2.2.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\nRequirement already satisfied: blis<0.5.0,>=0.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\nRequirement already satisfied: thinc==7.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\nRequirement already satisfied: numpy>=1.15.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.4)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\nRequirement already satisfied: setuptools in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (45.2.0.post20200210)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.42.1)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\nRequirement already satisfied: idna<2.9,>=2.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/dmpm/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\nRequirement already satisfied: zipp>=0.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.2.0)\n\u001B[38;5;2m✔ Download and installation successful\u001B[0m\nYou can now load the model via spacy.load('en_core_web_sm')\n\u001B[38;5;2m✔ Linking successful\u001B[0m\n/home/dmpm/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n/home/dmpm/anaconda3/lib/python3.7/site-packages/spacy/data/en\nYou can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "# Descarga el diccionario de inglés\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd8885a5-28a8-4554-a56c-a5993e4d89b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (2.2.5)\nRequirement already satisfied: spacy>=2.2.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from de_core_news_sm==2.2.5) (2.2.4)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\nRequirement already satisfied: blis<0.5.0,>=0.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\nRequirement already satisfied: thinc==7.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.42.1)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\nRequirement already satisfied: numpy>=1.15.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.22.0)\nRequirement already satisfied: setuptools in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (45.2.0.post20200210)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/dmpm/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2019.11.28)\nRequirement already satisfied: idna<2.9,>=2.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.25.8)\nRequirement already satisfied: zipp>=0.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.2.0)\n\u001B[38;5;2m✔ Download and installation successful\u001B[0m\nYou can now load the model via spacy.load('de_core_news_sm')\n\u001B[38;5;2m✔ Linking successful\u001B[0m\n/home/dmpm/anaconda3/lib/python3.7/site-packages/de_core_news_sm -->\n/home/dmpm/anaconda3/lib/python3.7/site-packages/spacy/data/de\nYou can now load the model via spacy.load('de')\n"
     ]
    }
   ],
   "source": [
    "# Descarga el diccionario alemán\n",
    " !python -m spacy download de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "667b9a34-dbca-4228-be9d-840318934572",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ahora cargamos los diccionarios en la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7eb788ee-9f98-408a-9363-8df18f20a400",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Carregando os dicionários\n",
    "spacy_german = spacy.load('de')\n",
    "spacy_english = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02fdbe15-85ec-4610-a0e8-2e29febc37ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Vamos a crear dos funciones para tokenizar los diccionarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f08c477d-f4c3-4342-9fe7-aa056f1da729",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función para tokenizar el diccionario de inglés\n",
    "def tokenize_english(text):\n",
    "    return [token.text for token in spacy_english.tokenizer(text)][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "002f0fec-eb15-482f-8f5e-7d70f12489cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# función de tokenización del diccionario alemán\n",
    "def tokenize_german(text):\n",
    "    return [token.text for token in spacy_german.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "576f23e5-ffde-462a-b042-f072f2a1d7df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ahora necesitamos crear el origen y el destino, es decir, el idioma de origen y el idioma de destino para nuestro traductor.\n",
    "\n",
    "Nuestro modelo debería traducirse del inglés al alemán. El inglés será la fuente (SOURCE) y el alemán será el destino (TARGET)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cec97cc7-6890-4efb-b335-5c990f6c1301",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lenguaje fuente\n",
    "SOURCE = Field(tokenize = tokenize_english, init_token = '<sos>', eos_token = '<eos>', lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a597276-6ba9-4441-bf2c-51a6b8810b1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lengua de llegada\n",
    "TARGET = Field(tokenize = tokenize_german, init_token = '<sos>', eos_token = '<eos>', lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4769fccc-9340-4506-b73c-3304d03bff64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Usamos split() del paquete Multi30k de torchtext para dividir los diccionarios en SOURCE y TARGET\n",
    "# y luego en entrenamiento, validación y prueba\n",
    "# Nota: Los datos se descargarán en el paquete Multi30k\n",
    "dados_treino, dados_valid, dados_teste = Multi30k.splits(exts = ('.en', '.de'), fields = (SOURCE, TARGET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95d65dbd-f37e-49d6-9bb5-70950c5634ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'bushes', 'many', 'near', 'outside', 'are', 'males', 'white', ',', 'young', 'two']\n['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']\n"
     ]
    }
   ],
   "source": [
    "# Visualización de datos de entrenamiento, Source y Target\n",
    "print(dados_treino.examples[0].src)\n",
    "print(dados_treino.examples[0].trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef61b1fa-fafb-475b-ae20-08fab1ac4bf2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Dataset de Treino: 29000\nTamanho do Dataset de Validação: 1014\nTamanho do Dataset de Teste: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño del conjunto de datos de entrenamiento: \" + str(len(dados_treino.examples)))\n",
    "print(\"Tamaño del conjunto de datos de validación: \" + str(len(dados_valid.examples)))\n",
    "print(\"Tamaño del conjunto de datos de prueba: \" + str(len(dados_teste.examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec549bf9-e7a2-49ad-802e-94d16ed13c6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Vamos a crear los vocabularios SOURCE y TARGET\n",
    "SOURCE.build_vocab(dados_treino, min_freq = 2)\n",
    "TARGET.build_vocab(dados_treino, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d51ba2c2-9a89-4d1f-8431-80f66034f1fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Vocabulário em Inglês (SOURCE): 5893\nTamanho do Vocabulário em Alemão (TARGET): 7855\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el tamaño de los vocabularios\n",
    "print(\"Tamaño del vocabulario en inglés (SOURCE): \" + str(len(SOURCE.vocab)))\n",
    "print(\"Tamaño del vocabulario alemán (TARGET): \" + str(len(TARGET.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "245b3683-e872-4aa6-9e9c-b9e1bd8e4577",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Construcción del modelo\n",
    "\n",
    "Crearemos 3 clases:\n",
    "\n",
    "- Codificador\n",
    "- decodificador\n",
    "- Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13de53b8-e338-45e9-9aec-815015688223",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clase para el codificador\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    # Método constructor\n",
    "    def __init__(self, input_dims, emb_dims, hid_dims, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Capas de modelo\n",
    "        self.hid_dims = hid_dims\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dims, emb_dims)\n",
    "        self.rnn = nn.LSTM(emb_dims, hid_dims, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    # Método forward para entrenamiento\n",
    "    def forward(self, src):\n",
    "        \n",
    "        # Ejecución del modelo\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (h, cell) = self.rnn(embedded)\n",
    "        \n",
    "        return h, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ed66793-d089-4f89-b860-c56c6278ee73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clase para el decodificador\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    # Método constructor\n",
    "    def __init__(self, output_dims, emb_dims, hid_dims, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Camadas do modelo\n",
    "        self.output_dims = output_dims\n",
    "        self.hid_dims = hid_dims\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dims, emb_dims)\n",
    "        self.rnn = nn.LSTM(emb_dims, hid_dims, n_layers, dropout = dropout)\n",
    "        self.fc_out = nn.Linear(hid_dims, output_dims)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    # Método forward  para entrenamiento\n",
    "    def forward(self, input, h, cell):\n",
    "              \n",
    "        # Ejecución del modelo\n",
    "        input = input.unsqueeze(0)   \n",
    "        embedded = self.dropout(self.embedding(input))     \n",
    "        output, (h, cell) = self.rnn(embedded, (h, cell))\n",
    "        pred = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        return pred, h, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5c5c103-2f75-431b-b2d8-198427f6547c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clase para el modelo Seq2Seq\n",
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    # método constructor\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Capas de modelo\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    # Método forward para entrenamiento\n",
    "    def forward(self, src, trg, teacher_forcing_rate = 0.5):\n",
    "        \n",
    "        # Ejecución del modelo\n",
    "        batch_size = trg.shape[1]\n",
    "        target_length = trg.shape[0]\n",
    "        target_vocab_size = self.decoder.output_dims\n",
    "        outputs = torch.zeros(target_length, batch_size, target_vocab_size).to(self.device)\n",
    "        h, cell = self.encoder(src)\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, target_length):\n",
    "\n",
    "            output, h, cell = self.decoder(input, h, cell)\n",
    "            outputs[t] = output\n",
    "            top = output.argmax(1) \n",
    "            input = trg[t] if (random.random() < teacher_forcing_rate) else top\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27d0ec28-7f8a-4ec8-9e2a-413fac43b096",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Definamos algunos hiperparámetros y los datos generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7770a4d0-ceef-45b0-b1b3-271af47e52b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparámetros\n",
    "batch_size = 32\n",
    "input_dimensions = len(SOURCE.vocab)\n",
    "output_dimensions = len(TARGET.vocab)\n",
    "encoder_embedding_dimensions = 256\n",
    "decoder_embedding_dimensions = 256\n",
    "hidden_layer_dimensions = 512\n",
    "num_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "epochs = 20\n",
    "grad_clip = 1\n",
    "lowest_validation_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2a86c30-9db2-4e89-a92e-394bc86436d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Heneradores de datos\n",
    "iterador_treino, iterador_valid, iterador_teste = BucketIterator.splits((dados_treino, dados_valid, dados_teste), \n",
    "                                                                        batch_size = batch_size, \n",
    "                                                                        device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4a32386-6073-4219-86a6-f5b8bb5c1812",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Aquí creamos el codificador, decodificador y modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c3cd5b3-5db7-4ed3-a787-287b75124502",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Instancia de codificador\n",
    "encod = Encoder(input_dimensions, \n",
    "                encoder_embedding_dimensions,\n",
    "                hidden_layer_dimensions, \n",
    "                num_layers, \n",
    "                encoder_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a40bd9b1-3e44-4623-8bcc-2e9440ac17e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Instancia de decodificador\n",
    "decod = Decoder(output_dimensions, \n",
    "                decoder_embedding_dimensions,\n",
    "                hidden_layer_dimensions, \n",
    "                num_layers, \n",
    "                decoder_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59230da2-9abe-4ba1-8071-2ebba61f1cd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Instancia de modelo\n",
    "modelo = Seq2Seq(encod, decod, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1faa91b-e510-478e-9b94-e49e60d190cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(7855, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=7855, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo creado\n",
    "modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e999823-98b8-40b9-9273-df41975bd0f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Definamos la función de inicialización de pesos, la función de costo y el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "016168d7-5c54-4c20-95b0-bf0542dab64e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Necesitamos una función para inicializar los pesos de las redes neuronales\n",
    "def inicializa_pesos(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f93b3cf0-f528-4bf5-830a-1708d1a2f8e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(7855, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=7855, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incluimos la función de inicialización del peso en el modelo.\n",
    "modelo.apply(inicializa_pesos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd8f2fa1-b636-40db-9a4c-1fe904e2be7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definimos la función de coste para calcular el error del modelo\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TARGET.vocab.stoi[TARGET.pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c73b3d3f-6d9e-42ea-a4ac-97ab492deae8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creamos el optimizador para actualizar los pesos del modelo con cada pase de entrenamiento\n",
    "optimizer = optim.Adam(modelo.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e90fd8f-4857-4552-96ab-ef006297afa0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Si bien no es obligatorio, la creación de funciones para la capacitación y evaluación de modelos ayuda a modularizar nuestro proceso de capacitación de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e8f2fc7-48d6-43e7-8cc9-cbf3b4cab2da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función para entrenar el modelo.\n",
    "def treina_modelo(modelo, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    # Iniciar el método de entrenamiento\n",
    "    modelo.train()\n",
    "    \n",
    "    # Inicializar error de época\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Iterador de bucle (generador de datos)\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        # Recopilamos datos de origen y destino\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        # Reseteamos los gradientes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Hacemos predicciones con el modelo\n",
    "        output = modelo(src, trg)\n",
    "        \n",
    "        # Ajustamos la forma de las previsiones\n",
    "        output_dims = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dims)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        # Calculamos el error del modelo\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        # Empezamos la backpropgation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Calculamos los gradientes de la derivada para actualizar los pesos\n",
    "        torch.nn.utils.clip_grad_norm_(modelo.parameters(), clip)\n",
    "        \n",
    "        # Aplicamos la actualización de peso\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Almacenamos el error de época\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5e68767-004a-431c-8964-1b0f05a9a00d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función para evaluar el modelo.\n",
    "def avalia_modelo(modelo, iterator, criterion):\n",
    "    \n",
    "    # Iniciar la función de evaluación\n",
    "    modelo.eval()\n",
    "    \n",
    "    # Inicializar error de época\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Hagamos predicciones con el modelo.\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # Iterador de bucle (generador de datos)\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            # Extraer origen y destino\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            # Pronóstico con el modelo\n",
    "            output = modelo(src, trg, 0)\n",
    "\n",
    "            # Ajusta las dimensiones de las previsiones\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            # Calcula el error del modelo\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            # Almacenar el error en la época.\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49dccf16-9146-4d3a-af3c-e346ba1317e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Entrenamiento del modelo\n",
    "\n",
    "La formación de modelos requiere mucho tiempo. Sea paciente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5245db1e-4aa7-43b0-9beb-5626b966694b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 48.0s\n\tErro em Treino: 4.7076\n\t Erro em Validação: 4.6512\nEpoch: 02 | Time: 47.0s\n\tErro em Treino: 3.9973\n\t Erro em Validação: 4.3468\nEpoch: 03 | Time: 47.0s\n\tErro em Treino: 3.6368\n\t Erro em Validação: 4.0514\nEpoch: 04 | Time: 48.0s\n\tErro em Treino: 3.3807\n\t Erro em Validação: 3.8883\nEpoch: 05 | Time: 48.0s\n\tErro em Treino: 3.1684\n\t Erro em Validação: 3.8140\nEpoch: 06 | Time: 48.0s\n\tErro em Treino: 2.9915\n\t Erro em Validação: 3.6792\nEpoch: 07 | Time: 47.0s\n\tErro em Treino: 2.8233\n\t Erro em Validação: 3.6726\nEpoch: 08 | Time: 48.0s\n\tErro em Treino: 2.6837\n\t Erro em Validação: 3.6291\nEpoch: 09 | Time: 48.0s\n\tErro em Treino: 2.5523\n\t Erro em Validação: 3.6190\nEpoch: 10 | Time: 47.0s\n\tErro em Treino: 2.4393\n\t Erro em Validação: 3.5998\nEpoch: 11 | Time: 47.0s\n\tErro em Treino: 2.3307\n\t Erro em Validação: 3.5683\nEpoch: 12 | Time: 48.0s\n\tErro em Treino: 2.2307\n\t Erro em Validação: 3.5983\nEpoch: 13 | Time: 48.0s\n\tErro em Treino: 2.1253\n\t Erro em Validação: 3.5880\nEpoch: 14 | Time: 47.0s\n\tErro em Treino: 2.0154\n\t Erro em Validação: 3.6639\nEpoch: 15 | Time: 48.0s\n\tErro em Treino: 1.9392\n\t Erro em Validação: 3.6356\nEpoch: 16 | Time: 48.0s\n\tErro em Treino: 1.8669\n\t Erro em Validação: 3.6467\nEpoch: 17 | Time: 48.0s\n\tErro em Treino: 1.7866\n\t Erro em Validação: 3.7214\nEpoch: 18 | Time: 48.0s\n\tErro em Treino: 1.7091\n\t Erro em Validação: 3.7471\nEpoch: 19 | Time: 47.0s\n\tErro em Treino: 1.6635\n\t Erro em Validação: 3.7931\nEpoch: 20 | Time: 48.0s\n\tErro em Treino: 1.6003\n\t Erro em Validação: 3.8183\n"
     ]
    }
   ],
   "source": [
    "# Recorra el número de épocas para entrenar el modelo\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Registrar la hora en que empezamos\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Capacitación\n",
    "    train_loss = treina_modelo(modelo, iterador_treino, optimizer, criterion, grad_clip)\n",
    "    \n",
    "    # Validación\n",
    "    valid_loss = avalia_modelo(modelo, iterador_valid, criterion)\n",
    "    \n",
    "    # Registra el tiempo cuando terminamos\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Verificamos el error mínimo y luego guardamos el modelo al verificar el modelo con mejor rendimiento.\n",
    "    if valid_loss < lowest_validation_loss:\n",
    "        lowest_validation_loss = valid_loss\n",
    "        torch.save(modelo.state_dict(), 'modelos/seq2seq.pt')\n",
    "    \n",
    "    # Print\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {np.round(end_time-start_time,0)}s')\n",
    "    print(f'\\tErro em Treino: {train_loss:.4f}')\n",
    "    print(f'\\t Erro em Validação: {valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e144aac-72e4-498a-8dbf-07f312519cfb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluación del modelo\n",
    "\n",
    "Con el modelo entrenado, lo evaluamos con datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f600b421-6605-41fc-9922-43e061fc9851",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el modelo entrenado\n",
    "modelo.load_state_dict(torch.load('modelos/seq2seq.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c418341e-a9d6-4e75-b243-2584883ad000",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluamos el modelo\n",
    "test_loss = avalia_modelo(modelo, iterador_teste, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b1d2249-4b66-4f5e-99a1-70d9712424a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro em Teste: 3.5024\n"
     ]
    }
   ],
   "source": [
    "# Print\n",
    "print(f'Erro em Teste: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b25d0085-c6a4-458b-8ffe-f3ab9e595543",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Traduciendo Idioma\n",
    "\n",
    "Modelo entrenado y evaluado, usémoslo para el propósito para el cual fue creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4150aa54-6138-4ae7-91c1-422cace6fc20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función para traducción de idiomas en 5 oraciones.\n",
    "def traduz_idioma(modelo, iterator, limit = 5):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # Bucle a través del iterador\n",
    "        for i, batch in enumerate(iterator):\n",
    "            \n",
    "            # Mientras estemos dentro del límite, traduciremos\n",
    "            if i < limit :\n",
    "                \n",
    "                # Extraemos SOURCE y TARGET\n",
    "                # Hacemos esto para poder comparar la traducción correcta con la predicción.\n",
    "                src = batch.src\n",
    "                trg = batch.trg\n",
    "\n",
    "                # Modelo de predicción\n",
    "                output = modelo(src, trg, 0)\n",
    "                \n",
    "                # Todas las predicciones\n",
    "                preds = torch.tensor([[torch.argmax(x).item()] for x in output])\n",
    "                \n",
    "                # Prints\n",
    "                print('Texto de Origem em Inglês: ' + str([SOURCE.vocab.itos[x] for x in src][1:-1][::-1]))\n",
    "                print('Texto de Destino em Alemão (Valor Esperado): ' + str([TARGET.vocab.itos[x] for x in trg][1:-1]))\n",
    "                print('Texto de Destino em Alemão (Valor Previsto): ' + str([TARGET.vocab.itos[x] for x in preds][1:-1]))\n",
    "                print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b213fb86-a809-49a1-8110-e7a989bcd7d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generemos texto aleatorio a partir de los datos disponibles.\n",
    "_, _, iterador_translate = BucketIterator.splits((dados_treino, dados_valid, dados_teste), \n",
    "                                                 batch_size = 1, \n",
    "                                                 device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b6126c7-95f3-47eb-881a-503baabbde4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto de Origem em Inglês: ['two', 'men', 'wearing', 'hats', '.']\nTexto de Destino em Alemão (Valor Esperado): ['zwei', 'männer', 'mit', 'mützen', '.']\nTexto de Destino em Alemão (Valor Previsto): ['zwei', 'männer', 'mit', 'schwarzen', 'haaren']\n\n\nTexto de Origem em Inglês: ['young', 'woman', 'climbing', 'rock', 'face']\nTexto de Destino em Alemão (Valor Esperado): ['junge', 'frau', 'klettert', 'auf', 'felswand']\nTexto de Destino em Alemão (Valor Previsto): ['eine', 'junge', 'frau', 'klettert', 'eine']\n\n\nTexto de Origem em Inglês: ['a', 'woman', 'is', 'playing', 'volleyball', '.']\nTexto de Destino em Alemão (Valor Esperado): ['eine', 'frau', 'spielt', 'volleyball', '.']\nTexto de Destino em Alemão (Valor Previsto): ['eine', 'frau', 'spielt', 'volleyball', '.']\n\n\nTexto de Origem em Inglês: ['three', 'men', 'are', 'walking', 'up', 'hill', '.']\nTexto de Destino em Alemão (Valor Esperado): ['drei', 'männer', 'gehen', 'bergauf', '.']\nTexto de Destino em Alemão (Valor Previsto): ['drei', 'männer', 'gehen', 'durch', 'einen']\n\n\nTexto de Origem em Inglês: ['an', 'army', 'officer', 'is', 'inspecting', 'something', '.']\nTexto de Destino em Alemão (Valor Esperado): ['ein', '<unk>', 'inspiziert', 'etwas', '.']\nTexto de Destino em Alemão (Valor Previsto): ['ein', '<unk>', 'schaut', 'in', 'die']\n\n\n"
     ]
    }
   ],
   "source": [
    "# Traducción de idiomas\n",
    "saida = traduz_idioma(modelo, iterador_translate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "254f64af-a18b-4532-bcb9-6192a6f56d52",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "¡Felicidades! Ahí lo tienes, tu traductor de textos con Machine Learning y NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6db0b6ea-2504-4e8c-b1a5-8f5c4aebecec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Fin"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Script-Traductor_Idiomas",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
